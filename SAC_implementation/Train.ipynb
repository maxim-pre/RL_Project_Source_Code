{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T14:13:33.772697Z",
     "start_time": "2025-12-11T14:13:30.359614Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 99868,
     "status": "ok",
     "timestamp": 1765546762278,
     "user": {
      "displayName": "Louie Trezise",
      "userId": "06890830520566349086"
     },
     "user_tz": 0
    },
    "id": "initial_id",
    "outputId": "c09cb12d-7a30-4220-d359-f446646239a5"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "from Agent import SACAgent\n",
    "from Networks import Critic, Actor\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44775fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "    %cd \"/content/drive/MyDrive/Python/Bath University/RL1_CW/Louie/SAC\"\n",
    "    !pip install swig\n",
    "    !pip install gymnasium[box2d]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6548b804db9363",
   "metadata": {
    "id": "2b6548b804db9363"
   },
   "source": [
    "# Training - Stage 1 - Complete Normal Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5092db120e7f227",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1343570,
     "status": "ok",
     "timestamp": 1765548359895,
     "user": {
      "displayName": "Louie Trezise",
      "userId": "06890830520566349086"
     },
     "user_tz": 0
    },
    "id": "a5092db120e7f227",
    "outputId": "85348365-6896-48fa-f738-b5c18884c8b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Random Exploration...\n",
      "Performing Actor Exploration...\n",
      "Running Episode 1...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      3\u001b[39m critic2 = Critic()\n\u001b[32m      5\u001b[39m agent = SACAgent(critic_network1=critic1,\n\u001b[32m      6\u001b[39m                  critic_network2=critic2,\n\u001b[32m      7\u001b[39m                  actor_network=actor,\n\u001b[32m   (...)\u001b[39m\u001b[32m     10\u001b[39m                  hardcore=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     11\u001b[39m                  max_buffer_length=\u001b[32m1_000_000\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_episodes\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdiscount_factor\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.99\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m            \u001b[49m\u001b[43mminibatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtau\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.005\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrandom_exploration_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10_000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m            \u001b[49m\u001b[43mactor_exploration_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m            \u001b[49m\u001b[43mvid_every\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop_after\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreset_optim\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreset_buffer\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# ====================== #\u001b[39;49;00m\n\u001b[32m     24\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcritic_lr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3e-4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m            \u001b[49m\u001b[43mactor_lr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3e-4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m            \u001b[49m\u001b[43malpha_lr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3e-4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcritic_grad_clip\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m            \u001b[49m\u001b[43mactor_grad_clip\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m            \u001b[49m\u001b[43malpha_grad_clip\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m            \u001b[49m\u001b[43mupdates_per_step\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/University_stuff/RL_CW_1/RL_sourcecode_submit/SAC_implementation/Agent.py:143\u001b[39m, in \u001b[36mSACAgent.learn\u001b[39m\u001b[34m(self, n_episodes, discount_factor, minibatch_size, tau, random_exploration_steps, actor_exploration_steps, vid_every, stop_after, reset_optim, reset_buffer, critic_lr, actor_lr, alpha_lr, critic_grad_clip, actor_grad_clip, alpha_grad_clip, updates_per_step)\u001b[39m\n\u001b[32m    141\u001b[39m         minibatch = \u001b[38;5;28mself\u001b[39m.sample_minibatch(minibatch_size)\n\u001b[32m    142\u001b[39m         \u001b[38;5;28mself\u001b[39m.update_critic_networks(minibatch, discount_factor, critic_grad_clip)\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mupdate_actor_network_and_alpha\u001b[49m\u001b[43m(\u001b[49m\u001b[43mminibatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactor_grad_clip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha_grad_clip\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    144\u001b[39m         \u001b[38;5;28mself\u001b[39m.soft_update_target_critics(tau)\n\u001b[32m    146\u001b[39m state = new_state\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/University_stuff/RL_CW_1/RL_sourcecode_submit/SAC_implementation/Agent.py:326\u001b[39m, in \u001b[36mSACAgent.update_actor_network_and_alpha\u001b[39m\u001b[34m(self, minibatch, actor_grad_clip, alpha_grad_clip)\u001b[39m\n\u001b[32m    324\u001b[39m actor_loss.backward()\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m actor_grad_clip > \u001b[32m0.0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclip_grad_norm_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mactor_network\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactor_grad_clip\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[38;5;28mself\u001b[39m.actor_optimizer.step()\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# Update alpha.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/University_stuff/RL_CW_1/RL_sourcecode_submit/env/lib/python3.12/site-packages/torch/nn/utils/clip_grad.py:43\u001b[39m, in \u001b[36m_no_grad.<locals>._no_grad_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_no_grad_wrapper\u001b[39m(*args, **kwargs):\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/University_stuff/RL_CW_1/RL_sourcecode_submit/env/lib/python3.12/site-packages/torch/nn/utils/clip_grad.py:232\u001b[39m, in \u001b[36mclip_grad_norm_\u001b[39m\u001b[34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[39m\n\u001b[32m    230\u001b[39m grads = [p.grad \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m parameters \u001b[38;5;28;01mif\u001b[39;00m p.grad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m    231\u001b[39m total_norm = _get_total_norm(grads, norm_type, error_if_nonfinite, foreach)\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m \u001b[43m_clip_grads_with_norm_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m total_norm\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/University_stuff/RL_CW_1/RL_sourcecode_submit/env/lib/python3.12/site-packages/torch/nn/utils/clip_grad.py:43\u001b[39m, in \u001b[36m_no_grad.<locals>._no_grad_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_no_grad_wrapper\u001b[39m(*args, **kwargs):\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/University_stuff/RL_CW_1/RL_sourcecode_submit/env/lib/python3.12/site-packages/torch/nn/utils/clip_grad.py:165\u001b[39m, in \u001b[36m_clip_grads_with_norm_\u001b[39m\u001b[34m(parameters, max_norm, total_norm, foreach)\u001b[39m\n\u001b[32m    160\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    161\u001b[39m grouped_grads: \u001b[38;5;28mdict\u001b[39m[\n\u001b[32m    162\u001b[39m     \u001b[38;5;28mtuple\u001b[39m[torch.device, torch.dtype], \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[Tensor]], \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m]]\n\u001b[32m    163\u001b[39m ] = _group_tensors_by_device_and_dtype([grads])  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m clip_coef = \u001b[43mmax_norm\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_norm\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1e-6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[38;5;66;03m# Note: multiplying by the clamped coef is redundant when the coef is clamped to 1, but doing so\u001b[39;00m\n\u001b[32m    167\u001b[39m \u001b[38;5;66;03m# avoids a `if clip_coef < 1:` conditional which can require a CPU <=> device synchronization\u001b[39;00m\n\u001b[32m    168\u001b[39m \u001b[38;5;66;03m# when the gradients do not reside in CPU memory.\u001b[39;00m\n\u001b[32m    169\u001b[39m clip_coef_clamped = torch.clamp(clip_coef, \u001b[38;5;28mmax\u001b[39m=\u001b[32m1.0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/University_stuff/RL_CW_1/RL_sourcecode_submit/env/lib/python3.12/site-packages/torch/_tensor.py:45\u001b[39m, in \u001b[36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(sargs):\n\u001b[32m     44\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(wrapped, sargs, *sargs, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/University_stuff/RL_CW_1/RL_sourcecode_submit/env/lib/python3.12/site-packages/torch/_tensor.py:1077\u001b[39m, in \u001b[36mTensor.__rdiv__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m   1073\u001b[39m \u001b[38;5;129m@_handle_torch_function_and_wrap_type_error_to_not_implemented\u001b[39m\n\u001b[32m   1074\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__rsub__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other: Union[\u001b[33m\"\u001b[39m\u001b[33mTensor\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mcomplex\u001b[39m]) -> \u001b[33m\"\u001b[39m\u001b[33mTensor\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1075\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _C._VariableFunctions.rsub(\u001b[38;5;28mself\u001b[39m, other)\n\u001b[32m-> \u001b[39m\u001b[32m1077\u001b[39m \u001b[38;5;129m@_handle_torch_function_and_wrap_type_error_to_not_implemented\u001b[39m\n\u001b[32m   1078\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__rdiv__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other: Union[\u001b[33m\"\u001b[39m\u001b[33mTensor\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mcomplex\u001b[39m]) -> \u001b[33m\"\u001b[39m\u001b[33mTensor\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1079\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reciprocal() * other\n\u001b[32m   1081\u001b[39m \u001b[34m__rtruediv__\u001b[39m = __rdiv__\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "actor = Actor()\n",
    "critic1 = Critic()\n",
    "critic2 = Critic()\n",
    "\n",
    "agent = SACAgent(critic_network1=critic1,\n",
    "                 critic_network2=critic2,\n",
    "                 actor_network=actor,\n",
    "                 log_alpha=0.0,\n",
    "                 device=device,\n",
    "                 hardcore=False,\n",
    "                 max_buffer_length=1_000_000)\n",
    "\n",
    "agent.learn(n_episodes=2000,\n",
    "            discount_factor=0.99,\n",
    "            minibatch_size=256,\n",
    "            tau=0.005,\n",
    "            random_exploration_steps=10_000,\n",
    "            actor_exploration_steps=1000,\n",
    "            vid_every=50,\n",
    "            stop_after=1,\n",
    "            reset_optim=True,\n",
    "            reset_buffer=True,\n",
    "            # ====================== #\n",
    "            critic_lr=3e-4,\n",
    "            actor_lr=3e-4,\n",
    "            alpha_lr=3e-4,\n",
    "            critic_grad_clip=1.0,\n",
    "            actor_grad_clip=1.0,\n",
    "            alpha_grad_clip=0.0,\n",
    "            updates_per_step=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a304fc2970b5af",
   "metadata": {
    "id": "34a304fc2970b5af"
   },
   "source": [
    "# Training - Stage 2 - Go Faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583fc7171a2de714",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4814139,
     "status": "ok",
     "timestamp": 1765553175110,
     "user": {
      "displayName": "Louie Trezise",
      "userId": "06890830520566349086"
     },
     "user_tz": 0
    },
    "id": "583fc7171a2de714",
    "outputId": "a37572c8-1bac-49ef-a800-6d3003be7a67"
   },
   "outputs": [],
   "source": [
    "agent.learn(n_episodes=500,\n",
    "            discount_factor=0.99,\n",
    "            minibatch_size=256,\n",
    "            tau=0.005,\n",
    "            random_exploration_steps=0,\n",
    "            actor_exploration_steps=0,\n",
    "            vid_every=50,\n",
    "            stop_after=None,\n",
    "            reset_optim=False,\n",
    "            reset_buffer=False,\n",
    "            # ====================== #\n",
    "            critic_lr=3e-4,\n",
    "            actor_lr=3e-4,\n",
    "            alpha_lr=3e-4,\n",
    "            critic_grad_clip=1.0,\n",
    "            actor_grad_clip=1.0,\n",
    "            alpha_grad_clip=0.0,\n",
    "            updates_per_step=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94c89d156a6355b",
   "metadata": {
    "id": "d94c89d156a6355b"
   },
   "source": [
    "# Training - Stage 3 - Complete Hardcore Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6943f8e106e61aa3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5640002,
     "status": "ok",
     "timestamp": 1765558815124,
     "user": {
      "displayName": "Louie Trezise",
      "userId": "06890830520566349086"
     },
     "user_tz": 0
    },
    "id": "6943f8e106e61aa3",
    "outputId": "99b1ef01-53a4-474c-907e-f6c2ad0f9694"
   },
   "outputs": [],
   "source": [
    "critic1 = Critic()\n",
    "critic2 = Critic()\n",
    "\n",
    "stage2_actor = Actor()\n",
    "stage2_actor.load_state_dict(torch.load(\"outputs/stage 2/actor_network.pth\", map_location=device))\n",
    "\n",
    "agent = SACAgent(critic_network1=critic1,\n",
    "                 critic_network2=critic2,\n",
    "                 actor_network=stage2_actor,\n",
    "                 log_alpha=0.0,\n",
    "                 device=device,\n",
    "                 hardcore=True,\n",
    "                 max_buffer_length=1_000_000)\n",
    "\n",
    "agent.learn(n_episodes=2000,\n",
    "            discount_factor=0.99,\n",
    "            minibatch_size=256,\n",
    "            tau=0.005,\n",
    "            random_exploration_steps=10_000,\n",
    "            actor_exploration_steps=1000,\n",
    "            vid_every=50,\n",
    "            stop_after=1,\n",
    "            reset_optim=True,\n",
    "            reset_buffer=True,\n",
    "            # ====================== #\n",
    "            critic_lr=3e-4,\n",
    "            actor_lr=3e-4,\n",
    "            alpha_lr=3e-4,\n",
    "            critic_grad_clip=1.0,\n",
    "            actor_grad_clip=1.0,\n",
    "            alpha_grad_clip=0.0,\n",
    "            updates_per_step=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a471babbddb9a79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T09:43:51.278367Z",
     "start_time": "2025-12-10T09:43:51.271108Z"
    },
    "id": "9a471babbddb9a79"
   },
   "source": [
    "# Training - Stage 4 - Complete Hardcore Consistently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3310be6a03d170bb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8347712,
     "status": "ok",
     "timestamp": 1765567162844,
     "user": {
      "displayName": "Louie Trezise",
      "userId": "06890830520566349086"
     },
     "user_tz": 0
    },
    "id": "3310be6a03d170bb",
    "outputId": "81d157b7-a705-4ba0-d090-7aa63def7dc8"
   },
   "outputs": [],
   "source": [
    "agent.learn(n_episodes=500,\n",
    "            discount_factor=0.99,\n",
    "            minibatch_size=256,\n",
    "            tau=0.005,\n",
    "            random_exploration_steps=0,\n",
    "            actor_exploration_steps=0,\n",
    "            vid_every=50,\n",
    "            stop_after=None,\n",
    "            reset_optim=False,\n",
    "            reset_buffer=False,\n",
    "            # ====================== #\n",
    "            critic_lr=3e-4,\n",
    "            actor_lr=3e-4,\n",
    "            alpha_lr=3e-4,\n",
    "            critic_grad_clip=1.0,\n",
    "            actor_grad_clip=1.0,\n",
    "            alpha_grad_clip=0.0,\n",
    "            updates_per_step=1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
